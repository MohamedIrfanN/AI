{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets peft accelerate bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:36:53.813728Z","iopub.execute_input":"2025-12-16T10:36:53.814107Z","iopub.status.idle":"2025-12-16T10:36:57.739206Z","shell.execute_reply.started":"2025-12-16T10:36:53.814073Z","shell.execute_reply":"2025-12-16T10:36:57.738107Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import random\nimport torch\n\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    GPT2Tokenizer,\n    GPT2LMHeadModel,\n    TrainingArguments,\n    Trainer\n)\nfrom peft import LoraConfig, get_peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:00.156358Z","iopub.execute_input":"2025-12-16T10:38:00.157314Z","iopub.status.idle":"2025-12-16T10:38:00.162334Z","shell.execute_reply.started":"2025-12-16T10:38:00.157280Z","shell.execute_reply":"2025-12-16T10:38:00.161491Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(\"CUDA:\", torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:02.295558Z","iopub.execute_input":"2025-12-16T10:38:02.295915Z","iopub.status.idle":"2025-12-16T10:38:02.300882Z","shell.execute_reply.started":"2025-12-16T10:38:02.295888Z","shell.execute_reply":"2025-12-16T10:38:02.300044Z"}},"outputs":[{"name":"stdout","text":"CUDA: True\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"dolly = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\nprint(\"Total Dolly samples:\", len(dolly))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:04.731162Z","iopub.execute_input":"2025-12-16T10:38:04.731996Z","iopub.status.idle":"2025-12-16T10:38:07.876163Z","shell.execute_reply.started":"2025-12-16T10:38:04.731968Z","shell.execute_reply":"2025-12-16T10:38:07.875364Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de5e76216aff4c71a9a530ab1e3324b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"databricks-dolly-15k.jsonl:   0%|          | 0.00/13.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d05e4b43b0004fc5a8cb44c8e71b0966"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/15011 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0306374b6479446d8d2436839f03e23c"}},"metadata":{}},{"name":"stdout","text":"Total Dolly samples: 15011\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(dolly[0].keys())\nprint(\"\\n--- SAMPLE ---\")\nprint(dolly[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:13.293753Z","iopub.execute_input":"2025-12-16T10:38:13.294430Z","iopub.status.idle":"2025-12-16T10:38:13.299578Z","shell.execute_reply.started":"2025-12-16T10:38:13.294404Z","shell.execute_reply":"2025-12-16T10:38:13.298901Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['instruction', 'context', 'response', 'category'])\n\n--- SAMPLE ---\n{'instruction': 'When did Virgin Australia start operating?', 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\", 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def format_dolly(example):\n    instruction = example[\"instruction\"].strip()\n    context = example[\"context\"]\n    response = example[\"response\"].strip()\n\n    text = f\"### Instruction:\\n{instruction}\\n\\n\"\n\n    if context and context.strip():\n        text += f\"### Input:\\n{context.strip()}\\n\\n\"\n\n    text += f\"### Response:\\n{response}\"\n    return {\"text\": text}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:15.945897Z","iopub.execute_input":"2025-12-16T10:38:15.946823Z","iopub.status.idle":"2025-12-16T10:38:15.951186Z","shell.execute_reply.started":"2025-12-16T10:38:15.946790Z","shell.execute_reply":"2025-12-16T10:38:15.950530Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"processed = [format_dolly(ex) for ex in dolly]\n\nrandom.shuffle(processed)\nprocessed = processed[:8000]   # still ideal\n\ntrain_dataset = Dataset.from_list(processed)\nprint(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:18.399260Z","iopub.execute_input":"2025-12-16T10:38:18.399563Z","iopub.status.idle":"2025-12-16T10:38:18.953245Z","shell.execute_reply.started":"2025-12-16T10:38:18.399540Z","shell.execute_reply":"2025-12-16T10:38:18.952342Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text'],\n    num_rows: 8000\n})\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(train_dataset[0][\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:20.719273Z","iopub.execute_input":"2025-12-16T10:38:20.719806Z","iopub.status.idle":"2025-12-16T10:38:20.724169Z","shell.execute_reply.started":"2025-12-16T10:38:20.719782Z","shell.execute_reply":"2025-12-16T10:38:20.723385Z"}},"outputs":[{"name":"stdout","text":"### Instruction:\nIdentify which instrument is string or percussion: Daf, Bandura\n\n### Response:\nBandura is string, Daf is percussion.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:22.807910Z","iopub.execute_input":"2025-12-16T10:38:22.808211Z","iopub.status.idle":"2025-12-16T10:38:25.064218Z","shell.execute_reply.started":"2025-12-16T10:38:22.808187Z","shell.execute_reply":"2025-12-16T10:38:25.063312Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aacbd14ca774a3188ff8fc0670d2393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e7ca48319448f8aa9bb926329d6210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d683559cf99f478581a990635d286557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae4f5994be924aa990971d2222796659"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2871e55caf54147bd898179491ccc36"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def tokenize(batch):\n    tokens = tokenizer(\n        batch[\"text\"],\n        truncation=True,\n        max_length=256,\n        padding=\"max_length\"\n    )\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n    return tokens\n\ntokenized_ds = train_dataset.map(\n    tokenize,\n    batched=True,\n    remove_columns=[\"text\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:29.290451Z","iopub.execute_input":"2025-12-16T10:38:29.290788Z","iopub.status.idle":"2025-12-16T10:38:43.208886Z","shell.execute_reply.started":"2025-12-16T10:38:29.290762Z","shell.execute_reply":"2025-12-16T10:38:43.208038Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027dbf2242ce402684c0af5250c9c132"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"print(tokenized_ds[0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:46.008146Z","iopub.execute_input":"2025-12-16T10:38:46.008443Z","iopub.status.idle":"2025-12-16T10:38:46.013475Z","shell.execute_reply.started":"2025-12-16T10:38:46.008421Z","shell.execute_reply":"2025-12-16T10:38:46.012654Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'attention_mask', 'labels'])\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:38:48.516081Z","iopub.execute_input":"2025-12-16T10:38:48.516380Z","iopub.status.idle":"2025-12-16T10:38:54.457596Z","shell.execute_reply.started":"2025-12-16T10:38:48.516358Z","shell.execute_reply":"2025-12-16T10:38:54.456790Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d92c931ad68849ba827d1536f34db493"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"467f36d3474c46808b0f89a1655c7241"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Embedding(50257, 1024)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,                  # ↑ from 8\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"c_attn\", \"c_proj\"]\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:39:11.798839Z","iopub.execute_input":"2025-12-16T10:39:11.799223Z","iopub.status.idle":"2025-12-16T10:39:11.998629Z","shell.execute_reply.started":"2025-12-16T10:39:11.799191Z","shell.execute_reply":"2025-12-16T10:39:11.997785Z"}},"outputs":[{"name":"stdout","text":"trainable params: 4,325,376 || all params: 359,148,544 || trainable%: 1.2043\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./gpt2-medium-dolly-lora\",\n    per_device_train_batch_size=4,     # ↓\n    gradient_accumulation_steps=4,     # ↑ effective batch = 16\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    fp16=True,\n    logging_steps=50,\n    save_steps=500,\n    save_total_limit=2,\n    report_to=\"none\",\n    label_names=[\"labels\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:39:46.427809Z","iopub.execute_input":"2025-12-16T10:39:46.428089Z","iopub.status.idle":"2025-12-16T10:39:46.458570Z","shell.execute_reply.started":"2025-12-16T10:39:46.428068Z","shell.execute_reply":"2025-12-16T10:39:46.457818Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:39:48.243159Z","iopub.execute_input":"2025-12-16T10:39:48.243978Z","iopub.status.idle":"2025-12-16T10:39:48.262026Z","shell.execute_reply.started":"2025-12-16T10:39:48.243949Z","shell.execute_reply":"2025-12-16T10:39:48.261204Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:39:50.360360Z","iopub.execute_input":"2025-12-16T10:39:50.360651Z","iopub.status.idle":"2025-12-16T11:16:08.373351Z","shell.execute_reply.started":"2025-12-16T10:39:50.360602Z","shell.execute_reply":"2025-12-16T11:16:08.372741Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 36:14, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>2.548400</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.431500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.319300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.383700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.311300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.357600</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.318800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.351900</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.313000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.373200</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.318200</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.300900</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.306500</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.290600</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.302200</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.269200</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.340700</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.322000</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.329000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.282300</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.321300</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.227800</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.278100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.326000</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.246800</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.310300</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.304900</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.318000</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>1.309600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.288600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1500, training_loss=1.3567216873168946, metrics={'train_runtime': 2177.5205, 'train_samples_per_second': 11.022, 'train_steps_per_second': 0.689, 'total_flos': 1.13038589952e+16, 'train_loss': 1.3567216873168946, 'epoch': 3.0})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"model.save_pretrained(\"./gpt2-medium-dolly-lora\")\ntokenizer.save_pretrained(\"./gpt2-medium-dolly-lora\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:25:27.255213Z","iopub.execute_input":"2025-12-16T11:25:27.255527Z","iopub.status.idle":"2025-12-16T11:25:27.444922Z","shell.execute_reply.started":"2025-12-16T11:25:27.255489Z","shell.execute_reply":"2025-12-16T11:25:27.444145Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"('./gpt2-medium-dolly-lora/tokenizer_config.json',\n './gpt2-medium-dolly-lora/special_tokens_map.json',\n './gpt2-medium-dolly-lora/vocab.json',\n './gpt2-medium-dolly-lora/merges.txt',\n './gpt2-medium-dolly-lora/added_tokens.json')"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"def generate_answer(model, tokenizer, prompt, max_new_tokens=150):\n    device = model.device\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        temperature=0.4,\n        top_p=0.9,\n        repetition_penalty=1.1,\n        do_sample=True,\n        eos_token_id=tokenizer.eos_token_id,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:25:36.252301Z","iopub.execute_input":"2025-12-16T11:25:36.253090Z","iopub.status.idle":"2025-12-16T11:25:36.258593Z","shell.execute_reply.started":"2025-12-16T11:25:36.253064Z","shell.execute_reply":"2025-12-16T11:25:36.257644Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"prompt = \"\"\"### Instruction:\nWho is Elon musk?\n\n### Response:\n\"\"\"\n\nprint(generate_answer(model, tokenizer, prompt))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:27:10.169094Z","iopub.execute_input":"2025-12-16T11:27:10.169648Z","iopub.status.idle":"2025-12-16T11:27:11.592144Z","shell.execute_reply.started":"2025-12-16T11:27:10.169600Z","shell.execute_reply":"2025-12-16T11:27:11.591547Z"}},"outputs":[{"name":"stdout","text":"### Instruction:\nWho is Elon musk?\n\n### Response:\nElon Musk (born August 25, 1954) is a British entrepreneur and inventor. He founded the Tesla Motors Company in California and has since become an investor in several other companies including SolarCity, SpaceX , and SpaceX.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"prompt = \"\"\"### Instruction:\nI have cold, What should i do?\n\n### Response:\n\"\"\"\n\nprint(generate_answer(model, tokenizer, prompt))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:45:32.485236Z","iopub.execute_input":"2025-12-16T11:45:32.485806Z","iopub.status.idle":"2025-12-16T11:45:33.434138Z","shell.execute_reply.started":"2025-12-16T11:45:32.485782Z","shell.execute_reply":"2025-12-16T11:45:33.433365Z"}},"outputs":[{"name":"stdout","text":"### Instruction:\nI have cold, What should i do?\n\n### Response:\nYou can take a shower and cool down with a hot cup of tea.  You can also use a warm bath to help you feel better.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"!zip -r gpt2_medium_dolly_lora_full.zip ./gpt2-medium-dolly-lora","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:36:17.724082Z","iopub.execute_input":"2025-12-16T11:36:17.724375Z","iopub.status.idle":"2025-12-16T11:36:24.192896Z","shell.execute_reply.started":"2025-12-16T11:36:17.724353Z","shell.execute_reply":"2025-12-16T11:36:24.192090Z"}},"outputs":[{"name":"stdout","text":"  adding: gpt2-medium-dolly-lora/ (stored 0%)\n  adding: gpt2-medium-dolly-lora/README.md (deflated 66%)\n  adding: gpt2-medium-dolly-lora/adapter_model.safetensors (deflated 7%)\n  adding: gpt2-medium-dolly-lora/adapter_config.json (deflated 56%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/ (stored 0%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/README.md (deflated 66%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/rng_state.pth (deflated 25%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/training_args.bin (deflated 52%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/adapter_model.safetensors (deflated 7%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/trainer_state.json (deflated 76%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/adapter_config.json (deflated 56%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/scaler.pt (deflated 60%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/optimizer.pt (deflated 9%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1000/scheduler.pt (deflated 56%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/ (stored 0%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/README.md (deflated 66%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/rng_state.pth (deflated 25%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/training_args.bin (deflated 52%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/adapter_model.safetensors (deflated 7%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/trainer_state.json (deflated 78%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/adapter_config.json (deflated 56%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/scaler.pt (deflated 60%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/optimizer.pt (deflated 9%)\n  adding: gpt2-medium-dolly-lora/checkpoint-1500/scheduler.pt (deflated 56%)\n  adding: gpt2-medium-dolly-lora/tokenizer_config.json (deflated 56%)\n  adding: gpt2-medium-dolly-lora/merges.txt (deflated 53%)\n  adding: gpt2-medium-dolly-lora/special_tokens_map.json (deflated 74%)\n  adding: gpt2-medium-dolly-lora/vocab.json (deflated 68%)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}