{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14160237,"sourceType":"datasetVersion","datasetId":9025412},{"sourceId":14163978,"sourceType":"datasetVersion","datasetId":9028121}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install transformers datasets accelerate evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:11.752193Z","iopub.execute_input":"2025-12-15T12:19:11.752526Z","iopub.status.idle":"2025-12-15T12:19:15.223278Z","shell.execute_reply.started":"2025-12-15T12:19:11.752503Z","shell.execute_reply":"2025-12-15T12:19:15.222582Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"   # prevents wandb prompts in Colab\n\nimport torch\n\nprint(\"CUDA:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU:\", torch.cuda.get_device_name(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:15.224891Z","iopub.execute_input":"2025-12-15T12:19:15.225140Z","iopub.status.idle":"2025-12-15T12:19:15.230328Z","shell.execute_reply.started":"2025-12-15T12:19:15.225116Z","shell.execute_reply":"2025-12-15T12:19:15.229658Z"}},"outputs":[{"name":"stdout","text":"CUDA: True\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from datasets import load_dataset\n\nDATA_PATH = \"/kaggle/input/bitcoin-data/bitcoin_dataset.jsonl\"  # if you're in this environment\n# In Colab, you will likely upload it, then use: DATA_PATH = \"/content/bitcoin_dev_gpt2_dataset.jsonl\"\n\nds = load_dataset(\"json\", data_files=DATA_PATH, split=\"train\")\nprint(ds)\nprint(ds[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:15.231064Z","iopub.execute_input":"2025-12-15T12:19:15.231425Z","iopub.status.idle":"2025-12-15T12:19:15.540720Z","shell.execute_reply.started":"2025-12-15T12:19:15.231382Z","shell.execute_reply":"2025-12-15T12:19:15.540141Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['instruction', 'input', 'response'],\n    num_rows: 7165\n})\n{'instruction': 'Summarize the following Bitcoin/Lightning/Liquid/Taproot Assets notes in 5-7 bullet points.', 'input': ' Foundations of the Lightning Network The scalability challenge and off-chain payment networks:  Limitations of Bitcoin Layer 1:  Block size: Limited to ~1 MB (up to ~4 MB effective with SegWit).  Block interval: A new block is mined every ~10 minutes.  Throughput: This results in an average of 3–7 transactions per second (tps), far lower than centralized payment systems such as Visa (~20,000+ tps).  These parameters ensure that running a Bitcoin node is possible for individuals with modest hardware, but they also create a bottleneck for scaling to global payment use.  Why not increase block size?  A natural suggestion is to raise the block size, allowing more transactions per block. However, larger blocks would:  Increase bandwidth and storage requirements for nodes, harder for ordinary users to run nodes.  Lead to centralization, as only powerful data centers could keep up.  Off-Chain Payment Networks as a Solution  Instead of pushing all payments onto the blockchain, the idea is to settle less frequently on-chain while allowing rapid, inexpensive transfers off-chain. This concept led to payment channels and, eventually, the Lightning Network.', 'response': '-  Foundations of the Lightning Network The scalability challenge and off-chain payment networks: Limitations of Bitcoin Layer 1: Block size: Limited to ~1 MB (up to ~4 MB effective with SegWit) Block interval: A new block is mined every ~10 minutes Throughput: This results in an average of 3–7 transactions per second (tps), far lower than centralized payment systems such as Visa (~20,000+ tps) These parameters ensure that running a Bitcoin node is possible for individuals with modest hardware, but they also create a bottleneck for scaling to global payment use Why not increase block size? A natural suggestion is to raise the block size, allowing more transactions per block However, larger blocks would:  Increase bandwidth and storage requirements for nodes, harder for ordinary users to run nodes'}\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"ds = ds.shuffle(seed=42)\nsplits = ds.train_test_split(test_size=0.02, seed=42)   # 2% validation\ntrain_ds = splits[\"train\"]\neval_ds  = splits[\"test\"]\n\nprint(\"Train:\", len(train_ds), \"Eval:\", len(eval_ds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:15.541389Z","iopub.execute_input":"2025-12-15T12:19:15.541673Z","iopub.status.idle":"2025-12-15T12:19:15.552295Z","shell.execute_reply.started":"2025-12-15T12:19:15.541654Z","shell.execute_reply":"2025-12-15T12:19:15.551606Z"}},"outputs":[{"name":"stdout","text":"Train: 7021 Eval: 144\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def format_example(ex):\n    instr = (ex.get(\"instruction\") or \"\").strip()\n    inp   = (ex.get(\"input\") or \"\").strip()\n    resp  = (ex.get(\"response\") or \"\").strip()\n\n    # This format is what GPT-2 learns to mimic.\n    # The \"###\" headers make the structure explicit and consistent.\n    if inp:\n        text = f\"### Instruction:\\n{instr}\\n\\n### Input:\\n{inp}\\n\\n### Response:\\n{resp}\\n\"\n    else:\n        text = f\"### Instruction:\\n{instr}\\n\\n### Response:\\n{resp}\\n\"\n\n    return {\"text\": text}\n\ntrain_ds = train_ds.map(format_example, remove_columns=train_ds.column_names)\neval_ds  = eval_ds.map(format_example, remove_columns=eval_ds.column_names)\n\nprint(train_ds[0][\"text\"][:600])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:15.554106Z","iopub.execute_input":"2025-12-15T12:19:15.554382Z","iopub.status.idle":"2025-12-15T12:19:15.568982Z","shell.execute_reply.started":"2025-12-15T12:19:15.554366Z","shell.execute_reply":"2025-12-15T12:19:15.568249Z"}},"outputs":[{"name":"stdout","text":"### Instruction:\nExplain these notes using one simple example (invent small numbers if needed) to show the flow.\n\n### Input:\nTapTweak — What It Is and How It Works  TapTweak is the cryptographic operation that combines a user’s internal public key with the Merkle root of all TapScript branches.  It creates a single new key — the Taproot output key (P(cid:0)ₐ(cid:0)ᵣₒₒ(cid:0)) — that commits to both the key path and script paths simultaneously.  This tweak ensures that:  all spending conditions (scripts) are cryptographically bound to the output, and  the Taproot address still looks like a simp\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\nMODEL_NAME = \"gpt2\"  # base GPT-2 (124M)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\n# GPT-2 has no pad token by default. Trainer needs padding for batches.\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\nmodel.config.pad_token_id = tokenizer.eos_token_id\n\nprint(\"Loaded:\", MODEL_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:15.569727Z","iopub.execute_input":"2025-12-15T12:19:15.570039Z","iopub.status.idle":"2025-12-15T12:19:16.315385Z","shell.execute_reply.started":"2025-12-15T12:19:15.570014Z","shell.execute_reply":"2025-12-15T12:19:16.314666Z"}},"outputs":[{"name":"stdout","text":"Loaded: gpt2\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"MAX_LEN = 768  \n\ndef tokenize(batch):\n    return tokenizer(\n        batch[\"text\"],\n        truncation=True,\n        max_length=MAX_LEN,\n        padding=\"max_length\",\n    )\n\ntrain_tok = train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\neval_tok  = eval_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n\nprint(train_tok[0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:16.316225Z","iopub.execute_input":"2025-12-15T12:19:16.316580Z","iopub.status.idle":"2025-12-15T12:19:16.498595Z","shell.execute_reply.started":"2025-12-15T12:19:16.316554Z","shell.execute_reply":"2025-12-15T12:19:16.498010Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6803dc185d5341e4b147314c219038e8"}},"metadata":{}},{"name":"stdout","text":"dict_keys(['input_ids', 'attention_mask'])\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False  # IMPORTANT: GPT-2 is NOT masked LM\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:16.499162Z","iopub.execute_input":"2025-12-15T12:19:16.499324Z","iopub.status.idle":"2025-12-15T12:19:16.503001Z","shell.execute_reply.started":"2025-12-15T12:19:16.499311Z","shell.execute_reply":"2025-12-15T12:19:16.502298Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nargs = TrainingArguments(\n    output_dir=\"gpt2-bitcoin-dev\",\n    overwrite_output_dir=True,\n\n    # training\n    num_train_epochs=2,\n    per_device_train_batch_size=4,     # ↑ from 2\n    gradient_accumulation_steps=4,     # effective batch = 16\n    learning_rate=5e-5,\n    weight_decay=0.01,\n\n    # eval/save/logging\n    eval_strategy=\"steps\",\n    eval_steps=200,\n    save_strategy=\"steps\",\n    save_steps=200,\n    logging_steps=50,\n    save_total_limit=2,\n\n    # performance\n    fp16=True,                         # P100 handles fp16 very well\n    report_to=\"none\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_tok,\n    eval_dataset=eval_tok,\n    data_collator=data_collator,\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:19:16.503678Z","iopub.execute_input":"2025-12-15T12:19:16.503864Z","iopub.status.idle":"2025-12-15T12:50:16.617435Z","shell.execute_reply.started":"2025-12-15T12:19:16.503850Z","shell.execute_reply":"2025-12-15T12:50:16.616878Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='878' max='878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [878/878 30:57, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>1.830200</td>\n      <td>1.561390</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.485000</td>\n      <td>1.226752</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.218700</td>\n      <td>1.016203</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.193800</td>\n      <td>0.923880</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=878, training_loss=1.5329748818434452, metrics={'train_runtime': 1859.2002, 'train_samples_per_second': 7.553, 'train_steps_per_second': 0.472, 'total_flos': 5503594070016000.0, 'train_loss': 1.5329748818434452, 'epoch': 2.0})"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"save_dir = \"gpt2-bitcoin-dev-final\"\ntrainer.save_model(save_dir)\ntokenizer.save_pretrained(save_dir)\n\nprint(\"Saved to:\", save_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:50:16.618246Z","iopub.execute_input":"2025-12-15T12:50:16.618785Z","iopub.status.idle":"2025-12-15T12:50:17.606816Z","shell.execute_reply.started":"2025-12-15T12:50:16.618749Z","shell.execute_reply":"2025-12-15T12:50:17.606039Z"}},"outputs":[{"name":"stdout","text":"Saved to: gpt2-bitcoin-dev-final\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline, StoppingCriteria, StoppingCriteriaList\n\nclass StopOnSubstrings(StoppingCriteria):\n    def __init__(self, tokenizer, stop_strings):\n        self.tokenizer = tokenizer\n        self.stop_ids = [tokenizer.encode(s, add_special_tokens=False) for s in stop_strings]\n\n    def __call__(self, input_ids, scores, **kwargs):\n        for stop in self.stop_ids:\n            if len(input_ids[0]) >= len(stop) and input_ids[0][-len(stop):].tolist() == stop:\n                return True\n        return False\n\n\ngen = pipeline(\n    \"text-generation\",\n    model=save_dir,\n    tokenizer=save_dir,\n    device=0 if torch.cuda.is_available() else -1\n)\n\nprompt = \"\"\"### Instruction:\nWhat is Bitcoin?\n\n### Response:\n\"\"\"\n\nstopping_criteria = StoppingCriteriaList([\n    StopOnSubstrings(\n        gen.tokenizer,\n        stop_strings=[\"### Instruction:\", \"### Input:\"]\n    )\n])\n\nout = gen(\n    prompt,\n    max_new_tokens=160,\n    do_sample=False,\n    no_repeat_ngram_size=4,\n    eos_token_id=gen.tokenizer.eos_token_id,\n    pad_token_id=gen.tokenizer.eos_token_id,\n    stopping_criteria=stopping_criteria\n)\n\nprint(out[0][\"generated_text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:50:17.607591Z","iopub.execute_input":"2025-12-15T12:50:17.607794Z","iopub.status.idle":"2025-12-15T12:50:19.769363Z","shell.execute_reply.started":"2025-12-15T12:50:17.607777Z","shell.execute_reply":"2025-12-15T12:50:19.768774Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nThe following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"### Instruction:\nWhat is Bitcoin?\n\n### Response:\nBitcoin is a distributed, digital money system built on cryptography and cryptography principles.  It is not pegged to any single Bitcoin output — it is a cryptographic, multi-asset system pegged to a Bitcoin UTXO.  It uses Proof-of-Work (PoW) mining to ensure that every transaction is valid, traceable, and verifiable.  Bitcoin’s Proof-of–Work (PoS) system ensures that transactions are not created by anyone else but by the hash of a public key, meaning every transaction is independently valid.  Bitcoin uses Proof-Of-Work (Proof-of-Reserves) to ensure that transactions are valid, traceability, and verifiability, not by anyone else.  Bitcoin Core Concepts  Bitcoin Core is a Bitcoin-native\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"device = 0 if torch.cuda.is_available() else -1\n\n# Base GPT-2\nbase_gen = pipeline(\n    \"text-generation\",\n    model=\"gpt2\",\n    tokenizer=\"gpt2\",\n    device=device\n)\n\nbase_stop = StoppingCriteriaList([\n    StopOnSubstrings(base_gen.tokenizer, [\"### Instruction:\", \"### Input:\"])\n])\n\n# Fine-tuned GPT-2\nft_gen = pipeline(\n    \"text-generation\",\n    model=save_dir,\n    tokenizer=save_dir,\n    device=device\n)\n\nft_stop = StoppingCriteriaList([\n    StopOnSubstrings(ft_gen.tokenizer, [\"### Instruction:\", \"### Input:\"])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:50:19.770092Z","iopub.execute_input":"2025-12-15T12:50:19.770344Z","iopub.status.idle":"2025-12-15T12:50:21.051039Z","shell.execute_reply.started":"2025-12-15T12:50:19.770325Z","shell.execute_reply":"2025-12-15T12:50:21.050437Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"def compare(prompt, max_new_tokens=180):\n    print(\"=\" * 90)\n    print(\"PROMPT:\")\n    print(prompt)\n    print(\"=\" * 90)\n\n    base_out = base_gen(\n        prompt,\n        max_new_tokens=max_new_tokens,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9,\n    )[0][\"generated_text\"]\n\n    ft_out = ft_gen(\n        prompt,\n        max_new_tokens=max_new_tokens,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9,\n    )[0][\"generated_text\"]\n\n    print(\"\\n--- BASE GPT-2 OUTPUT ---\\n\")\n    print(base_out)\n\n    print(\"\\n--- FINE-TUNED GPT-2 OUTPUT ---\\n\")\n    print(ft_out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:50:21.051814Z","iopub.execute_input":"2025-12-15T12:50:21.052044Z","iopub.status.idle":"2025-12-15T12:50:21.056834Z","shell.execute_reply.started":"2025-12-15T12:50:21.052021Z","shell.execute_reply":"2025-12-15T12:50:21.056206Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"prompt1 = \"\"\"### Instruction:\nWhat is Bitcoin?\n\n### Response:\n\"\"\"\ncompare(prompt1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:50:21.058972Z","iopub.execute_input":"2025-12-15T12:50:21.059167Z","iopub.status.idle":"2025-12-15T12:50:24.693942Z","shell.execute_reply.started":"2025-12-15T12:50:21.059150Z","shell.execute_reply":"2025-12-15T12:50:24.693178Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"==========================================================================================\nPROMPT:\n### Instruction:\nWhat is Bitcoin?\n\n### Response:\n\n==========================================================================================\n\n--- BASE GPT-2 OUTPUT ---\n\n### Instruction:\nWhat is Bitcoin?\n\n### Response:\n\nBitcoin is a digital currency. It is an alternative to the traditional currency. It is decentralized and can be used to create any kind of digital currency that can be used for any purpose. It is based on Bitcoin and is a digital currency. The primary purpose of Bitcoin is to make money. The main purpose of Bitcoin is to make money and to be able to buy and sell anything. It is a decentralized currency that can be used to purchase anything.\n\n### Response:\n\nBitcoin is a digital currency. It is a digital currency. It is a decentralized currency that can be used to purchase anything. It is a decentralized currency that can be used to purchase anything.\n\n### Response:\n\nBitcoin is a digital currency. It is a digital currency. It is a decentralized currency that can be used to purchase anything. It is a decentralized currency that can be used to purchase anything\n\n--- FINE-TUNED GPT-2 OUTPUT ---\n\n### Instruction:\nWhat is Bitcoin?\n\n### Response:\nBitcoin is a distributed, digital money system built on cryptography and cryptography principles.  It is a trust-based system that operates off-chain, using cryptography as the foundation.  It’s not pegged to paper but is guaranteed to remain secure over time.  It is digital only, meaning no one can create or manipulate it.  Anyone can verify its validity, but it must remain private and trustless.  Why Bitcoin?\nWhy Use Bitcoin Instead of Traditional Money?  Traditional Money: Instead of fiat money, which governments control, today’s money is controlled by a trust-based system.  Instead of controlling banks or banks, governments control the means of making money happen.  This system is based on trust in institutions, not money.  Instead of controlling banks or banks, governments control the means of making money happen.\n\n### Response:\nBitcoin is a\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"prompt2 = \"\"\"### Instruction:\nExplain how a Bitcoin transaction is verified.\n\n### Response:\n\"\"\"\ncompare(prompt2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:50:24.694571Z","iopub.execute_input":"2025-12-15T12:50:24.694887Z","iopub.status.idle":"2025-12-15T12:50:26.691192Z","shell.execute_reply.started":"2025-12-15T12:50:24.694864Z","shell.execute_reply":"2025-12-15T12:50:26.690445Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"==========================================================================================\nPROMPT:\n### Instruction:\nExplain how a Bitcoin transaction is verified.\n\n### Response:\n\n==========================================================================================\n\n--- BASE GPT-2 OUTPUT ---\n\n### Instruction:\nExplain how a Bitcoin transaction is verified.\n\n### Response:\n\nIf you have any questions or concerns about our service or our product, please contact us at support@bitcoin.com.\n\n--- FINE-TUNED GPT-2 OUTPUT ---\n\n### Instruction:\nExplain how a Bitcoin transaction is verified.\n\n### Response:\nVerification relies on comparing a Taproot output with the witness pubkey, ensuring the proof is cryptographically secure.  If the signature matches the revealed Taproot public key, the witness pubkey is valid.  If the signature does not match, the proof is invalid.  Key Derivation  Each output key has a unique cryptographic identifier derived from the hash of the previous output key: H_pubkey → private key derived from previous H_pubkey.  The resulting key pair can be forged using:  A Schnorr signature: H_SchnorrSignature = H_pubkey + e × G.  Derivation using a pairwise key tweak: P_weak = P_weak + e × P_e^{P_weak} × G  Key Derivation using a nonce: R_key = R_pubkey × G  This creates: \n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"prompt3 = \"\"\"### Instruction:\nExplain what an HTLC is and why it is needed in the Lightning Network.\n\n### Response:\n\"\"\"\n\ncompare(prompt3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:50:26.692049Z","iopub.execute_input":"2025-12-15T12:50:26.692287Z","iopub.status.idle":"2025-12-15T12:50:30.244763Z","shell.execute_reply.started":"2025-12-15T12:50:26.692264Z","shell.execute_reply":"2025-12-15T12:50:30.243873Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"==========================================================================================\nPROMPT:\n### Instruction:\nExplain what an HTLC is and why it is needed in the Lightning Network.\n\n### Response:\n\n==========================================================================================\n\n--- BASE GPT-2 OUTPUT ---\n\n### Instruction:\nExplain what an HTLC is and why it is needed in the Lightning Network.\n\n### Response:\n\nWe have received this question from an engineer with the Linux Foundation.\n\nWe would like to send an email to you with further information.\n\nThe Linux Foundation has the following guidelines on how to respond to questions about the Lightning Network.\n\n1. If you have an answer to a question you would like to have answered, please send us an email.\n\n2. If you have an answer to a question you would like to have answered, please send us an email.\n\n3. If you have an answer to a question you would like to have answered, please send us an email.\n\n4. If you have an answer to a question you would like to have answered, please send us an email.\n\n5. If you have an answer to a question you would like to have answered, please send us an email.\n\n6. If you\n\n--- FINE-TUNED GPT-2 OUTPUT ---\n\n### Instruction:\nExplain what an HTLC is and why it is needed in the Lightning Network.\n\n### Response:\nHTLCs are a new type of payment channel between sender and receiver that allows Bitcoin Layer 1 (the Lightning Network) to offer fast, high-speed payments.  Unlike traditional payment channels, which rely on HTLCs, HTLCs allow users to send money instantly and securely over the Lightning Network.  How HTLCs Work  A user creates an HTLC by sending BTC to a payment channel operator.  The operator verifies the sender’s public key (PublicKeyHash or SHA256).  The payment is forwarded over the Lightning Network using the same public key.  The sender learns the preimage R (which includes the SHA256 hash) and the payment hash H(R).  After this, the sender’s funds are confirmed instantly.  HTLCs allow instant, low-cost payments over the Lightning Network.  Why It Matters  HTLC\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"prompt4 = \"\"\"### Instruction:\nWhat is taproot assets?\n\n### Response:\n\"\"\"\ncompare(prompt4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:54:15.249679Z","iopub.execute_input":"2025-12-15T12:54:15.250378Z","iopub.status.idle":"2025-12-15T12:54:18.783025Z","shell.execute_reply.started":"2025-12-15T12:54:15.250353Z","shell.execute_reply":"2025-12-15T12:54:18.782341Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"==========================================================================================\nPROMPT:\n### Instruction:\nWhat is taproot assets?\n\n### Response:\n\n==========================================================================================\n\n--- BASE GPT-2 OUTPUT ---\n\n### Instruction:\nWhat is taproot assets?\n\n### Response:\n\nI have a small set of taproot assets. I have not used them to generate a program, but it is my personal favorite tool.\n\n### Usage:\n\n### Usage:\n\nimport taproot\n\nimport taproot.common.common.main\n\nimport taproot.common.common.tapp\n\nimport taproot.common.common.tapp.TappMain\n\nimport taproot.common.common.tapp.TappMain\n\nimport taproot.common.common.tapp.TappMain.Tapp\n\nimport taproot.common.common.tapp.TappMain.TappMain.TappMain\n\nimport taproot.common.common.tapp.TappMain.TappMain\n\nimport taproot.common.common.tapp.TappMain.T\n\n--- FINE-TUNED GPT-2 OUTPUT ---\n\n### Instruction:\nWhat is taproot assets?\n\n### Response:\nTaproot Assets is a Bitcoin-native, proof-of-work implementation built on Merkle roots and Merkle inclusion paths.  It uses Schnorr signatures instead of SHA-256, improves on Schnorr for smaller keys, and reduces the number of checks required for efficient multi-sig. Features  Multiple output types (signed, unsigned, and Merkle commitments).  Full proof verification for assets, blocks, and multisig.  Privacy and scalability.  Supports multi-signature support.  Flexible contract model that simplifies asset issuance and settlement.  Uses Schnorr instead of SHA for smaller keys.  What is Taproot Asset?  Taproot Assets is a Bitcoin-native, proof-of-work implementation built on Merkle roots and Merkle inclusion paths. It uses Schnorr signatures instead of SHA-256, improves on\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"prompt6 = \"\"\"### Instruction:\nWhat is lightning network\n\n### Response:\n\"\"\"\ncompare(prompt6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:55:40.585185Z","iopub.execute_input":"2025-12-15T12:55:40.585910Z","iopub.status.idle":"2025-12-15T12:55:44.019353Z","shell.execute_reply.started":"2025-12-15T12:55:40.585882Z","shell.execute_reply":"2025-12-15T12:55:44.018336Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"==========================================================================================\nPROMPT:\n### Instruction:\nWhat is lightning network\n\n### Response:\n\n==========================================================================================\n\n--- BASE GPT-2 OUTPUT ---\n\n### Instruction:\nWhat is lightning network\n\n### Response:\n\nWhat is lightning network\n\n### Example:\n\n### Instruction:\n\nWhat is lightning network\n\n### Response:\n\nWhat is lightning network\n\n### Example:\n\n### Instruction:\n\nWhat is lightning network\n\n### Response:\n\nWhat is lightning network\n\n### Example:\n\n### Instruction:\n\nWhat is lightning network\n\n### Response:\n\nWhat is lightning network\n\n### Example:\n\n### Instruction:\n\nWhat is lightning network\n\n### Response:\n\nWhat is lightning network\n\n### Example:\n\n### Instruction:\n\nWhat is lightning network\n\n### Response:\n\nWhat is lightning network\n\n### Example:\n\n### Instruction:\n\nWhat is lightning network\n\n### Response:\n\nWhat is lightning network\n\n### Example:\n\n### Instruction:\n\nWhat\n\n--- FINE-TUNED GPT-2 OUTPUT ---\n\n### Instruction:\nWhat is lightning network\n\n### Response:\nLightning Network is a peer-to-peer (P2P) payment network built on Bitcoin Layer 1.  It enables instant, low-fee payments across the Lightning Network without intermediaries or costly server-side intermediaries.  It supports:  Liquidity settlement (locking BTC in a channel to return BTC to the main network).  Payments over the Lightning Network with Lightning Network features like confirmation, timeouts, and HTLCs.  Channel Setup  A channel is a Lightning Network feature that allows a user to pay in a specific channel by exchanging BTC for Bitcoin on the main network.  The conversion is atomic and takes no seconds.  The conversion process ensures that each recipient’s channel is unique, secure, and private while the payer’s funds remain unspent.  Mechanism  Channel Setup  A user opens a Lightning channel and pays the user\n","output_type":"stream"}],"execution_count":41}]}